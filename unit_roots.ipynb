{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for unit roots in a time series \n",
    "\n",
    "##### Jorge De Le√≥n \n",
    "##### Universidad del Rosario\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We extract the data from a PDF and convert it into a .xlsx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn\n",
    "from arch.unitroot import PhillipsPerron\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity = pd.read_excel(\"velocity.xlsx\")\n",
    "velocity['time'] = velocity.index + 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have these 3 models:\n",
    "\n",
    "- $y_{t} = \\gamma _{1}y_{t-1} + \\epsilon _{t}$ Random walk\n",
    "- $y_{t} = \\gamma_{0} + \\gamma _{1}y_{t-1} + \\epsilon _{t}$ Randon walk with a drift\n",
    "- $y_{t} = \\gamma_{0} + \\gamma _{1}y_{t-1} + \\gamma_{2} t +\\epsilon _{t}$ randon walk with a drift and time trend\n",
    "\n",
    "Now we estimate those regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>velocity</td>     <th>  R-squared:         </th> <td>   0.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1268.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 22 Feb 2023</td> <th>  Prob (F-statistic):</th> <td>1.31e-65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:34:57</td>     <th>  Log-Likelihood:    </th> <td>  27.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    91</td>      <th>  AIC:               </th> <td>  -49.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    88</td>      <th>  BIC:               </th> <td>  -42.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>    0.2661</td> <td>    0.188</td> <td>    1.414</td> <td> 0.161</td> <td>   -0.108</td> <td>    0.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>velocity.shift(1)</th> <td>    0.9143</td> <td>    0.046</td> <td>   20.084</td> <td> 0.000</td> <td>    0.824</td> <td>    1.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time</th>              <td>   -0.0019</td> <td>    0.002</td> <td>   -1.107</td> <td> 0.271</td> <td>   -0.005</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 8.315</td> <th>  Durbin-Watson:     </th> <td>   2.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.016</td> <th>  Jarque-Bera (JB):  </th> <td>  16.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.157</td> <th>  Prob(JB):          </th> <td>0.000267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.059</td> <th>  Cond. No.          </th> <td>    549.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               velocity   R-squared:                       0.966\n",
       "Model:                            OLS   Adj. R-squared:                  0.966\n",
       "Method:                 Least Squares   F-statistic:                     1268.\n",
       "Date:                Wed, 22 Feb 2023   Prob (F-statistic):           1.31e-65\n",
       "Time:                        12:34:57   Log-Likelihood:                 27.973\n",
       "No. Observations:                  91   AIC:                            -49.95\n",
       "Df Residuals:                      88   BIC:                            -42.41\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept             0.2661      0.188      1.414      0.161      -0.108       0.640\n",
       "velocity.shift(1)     0.9143      0.046     20.084      0.000       0.824       1.005\n",
       "time                 -0.0019      0.002     -1.107      0.271      -0.005       0.002\n",
       "==============================================================================\n",
       "Omnibus:                        8.315   Durbin-Watson:                   2.045\n",
       "Prob(Omnibus):                  0.016   Jarque-Bera (JB):               16.457\n",
       "Skew:                          -0.157   Prob(JB):                     0.000267\n",
       "Kurtosis:                       5.059   Cond. No.                         549.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1 = smf.ols(formula = 'velocity ~ 0 + velocity.shift(1)', data=velocity).fit()\n",
    "mod2 = smf.ols(formula = 'velocity ~ velocity.shift(1)', data=velocity).fit()\n",
    "mod3 = smf.ols(formula = 'velocity ~ velocity.shift(1) + time', data=velocity).fit()\n",
    "\n",
    "# Can use the following metod to see the results of any of the models above \n",
    "mod3.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phillips Perron test for Unit Roots \n",
    " - pp1: model with no time trend and no constant\n",
    " - pp2: model with constant \n",
    " - pp3: model wit time trend and a constant\n",
    "\n",
    "\n",
    " Note: Every model uses just 1 lag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Phillips-Perron Test (Z-tau)    \n",
      "=====================================\n",
      "Test Statistic                 -1.835\n",
      "P-value                         0.688\n",
      "Lags                                1\n",
      "-------------------------------------\n",
      "\n",
      "Trend: Constant and Linear Time Trend\n",
      "Critical Values: -4.06 (1%), -3.46 (5%), -3.16 (10%)\n",
      "Null Hypothesis: The process contains a unit root.\n",
      "Alternative Hypothesis: The process is weakly stationary.\n"
     ]
    }
   ],
   "source": [
    "pp1 = PhillipsPerron(velocity[\"velocity\"], lags = 1,  trend = \"n\")\n",
    "pp2 = PhillipsPerron(velocity[\"velocity\"], lags = 1,  trend = \"c\")\n",
    "pp3 = PhillipsPerron(velocity[\"velocity\"], lags = 1,  trend = \"ct\")\n",
    "\n",
    "# To see the result:\n",
    "print(pp3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montecarlo simulation \n",
    "\n",
    "- $Y_{t} = \\alpha + \\beta t + \\hat{u_{t}}$\n",
    "\n",
    "1000 obs and 1000 rep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345) #Seed \n",
    "repeticiones = 1000\n",
    "Obs = 100\n",
    "r1 = []\n",
    "r2 = []\n",
    "r3 = []\n",
    "\n",
    "residuals = []\n",
    "residuals1 = []\n",
    "alpha = 0\n",
    "beta = 0\n",
    "A = 0\n",
    "be = 0\n",
    "\n",
    "betas_gorro = []\n",
    "alphas_gorro = []\n",
    "R_scuared = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we replace Y with the formmula of the model \n",
    "\n",
    "for z in range(repeticiones):\n",
    "    Y = []\n",
    "    X = []\n",
    "    alpha = 0\n",
    "    beta = 0\n",
    "    Obs = 100\n",
    "    for i in range(Obs):\n",
    "        Y.append(0)\n",
    "        X.append(i+1)\n",
    "    \n",
    "    for i in range(Obs):\n",
    "        u  = np.random.normal(loc=0, scale=1)\n",
    "        if i == 0:\n",
    "            Y[i] = u\n",
    "        else:\n",
    "            Y[i] = Y[i-1] + u\n",
    "\n",
    "    dic = {'Y' : Y, 'X': X}\n",
    "    panel = pd.DataFrame(data=dic) #Data Frame\n",
    "    y = panel[\"Y\"].values.reshape(-1, 1)\n",
    "    x = panel[\"X\"].values.reshape(-1, 1)\n",
    "\n",
    "    reg1 = LinearRegression().fit(x, y)\n",
    "    #R_scuared.append(float(reg1.score(x,y)))\n",
    "    preds = reg1.predict(x)\n",
    "    R_scuared.append(r2_score(y, preds))\n",
    "\n",
    "    residuals = y - preds\n",
    "\n",
    "    residuals1 = sm.tsa.acf(residuals)\n",
    "    r1.append(residuals1[1])\n",
    "    r2.append(residuals1[2])\n",
    "    r3.append(residuals1[3])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos replicados del paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4415277141440973\n",
      "0.8798132075848984\n",
      "0.7696503567359734\n",
      "0.6689538175809225\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(R_scuared))\n",
    "print(np.mean(r1))\n",
    "print(np.mean(r2))\n",
    "print(np.mean(r3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de 1000 repeticiones con 20 observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(repeticiones):\n",
    "    Y = []\n",
    "    X = []\n",
    "    alpha = 0\n",
    "    beta = 0\n",
    "    Obs = 20\n",
    "    for i in range(Obs):\n",
    "        Y.append(0)\n",
    "        X.append(i+1)\n",
    "    \n",
    "    for i in range(Obs):\n",
    "        u  = np.random.normal(loc=0, scale=1)\n",
    "        if i == 0:\n",
    "            Y[i] = u\n",
    "        else:\n",
    "            Y[i] = Y[i-1] + u\n",
    "\n",
    "    dic = {'Y' : Y, 'X': X}\n",
    "    panel = pd.DataFrame(data=dic) #Data Frame\n",
    "    y = panel[\"Y\"].values.reshape(-1, 1)\n",
    "    x = panel[\"X\"].values.reshape(-1, 1)\n",
    "\n",
    "    reg1 = LinearRegression().fit(x, y)\n",
    "    #R_scuared.append(float(reg1.score(x,y)))\n",
    "    preds = reg1.predict(x)\n",
    "    R_scuared.append(r2_score(y, preds))\n",
    "\n",
    "    residuals = y - preds\n",
    "\n",
    "    residuals1 = sm.tsa.acf(residuals)\n",
    "    r1.append(residuals1[1])\n",
    "    r2.append(residuals1[2])\n",
    "    r3.append(residuals1[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We obtain the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4222633620007054\n",
      "0.4858723618135954\n",
      "0.16460345862813203\n",
      "-0.043182226065671764\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(R_scuared))\n",
    "print(np.mean(r1))\n",
    "print(np.mean(r2))\n",
    "print(np.mean(r3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be3b2a8aac26c42044c9d23f04a79af7af72d0de392e42af99ddd24cb8435e3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
